{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pufffss1/machine-learning-technologies/blob/main/%D0%9B%D0%B5%D0%BA%D1%86%D0%B8%D1%8F%203\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Подготовлено с использованием материалов тематических курсов Шевлякова А.Н., Пономаревой Ю., Созыкина А., СберУниверситета, Университета Иннополис, НИУ ВШЭ и др.*"
      ],
      "metadata": {
        "id": "wKxBPMrDh00A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Лекция 3.** Введение в искусственные нейронные сети"
      ],
      "metadata": {
        "id": "yHLiOsxyiCDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Искусственные нейронные сети**"
      ],
      "metadata": {
        "id": "GcaTt51Y7wcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Одним из наиболее популярных и перспективных методов машинного обучения являются искусственные нейронные сети.\n",
        "\n",
        "**Искусственная нейронная сеть** (ИНС) (англ. Artificial neural network, ANN) – это упрощенная модель биологической нейронной сети (головного мозга), представляющая собой совокупность искусственных нейронов, взаимодействующих между собой.\n",
        "\n",
        "<img src=\"https://i.ibb.co/20zFx3bY/image.png\" width=500>\n",
        "\n",
        "Нейронные сети используются в многочисленных областях машинного обучения и весьма успешно решают проблемы различной сложности.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **История ИНС**\n",
        "\n",
        "Представление о нейронных сетях как основном способе создания искусственного интеллекта сложилось далеко не сразу.\n",
        "\n",
        "В 1943 году в статье «Логическое исчисление идей, относящихся к нервной активности» У. Мак-Каллок и У. Питтс ввели понятие искусственной нейронной сети и предложили модель искусственного нейрона.\n",
        "\n",
        "Эти идеи несколько лет спустя развил американский нейрофизиолог Фрэнк Розенблатт. Он предложил схему устройства, моделирующего процесс человеческого восприятия, и назвал его «перцептроном».\n",
        "\n",
        "<img src=\"https://i.ibb.co/svVvBPT6/image.png\" width=170>\n",
        "\n",
        "В виде компьютерной системы нейронная сеть была впервые реализована Розенблаттом в 1960 году. Он создал «Марк-1» - программно-аппаратный комплекс, реализующий простую нейронную сеть с одним слоем.\n",
        "\n",
        "Однако волна энтузиазма 60-х годов в отношении искусственных\n",
        "нейронных сетей сменилась скепсисом из-за трудностей в совершении определенных логических операций и невозможности получать практические результаты. Доминирующим подходом для создания искусственного интеллекта стали экспертные системы, являющиеся по сути продвинутыми интерактивными энциклопедиями знаний в той или иной сфере.\n",
        "\n",
        "В конце XX в. появились **глубокие** нейронные сети, т.е. сети с количеством внутренних слоев более одного. Сначала количество слоев в таких нейронных сетях составляло единицы. Но в силу эффективности подхода по увеличению количества слоев быстро появились нейронные сети с числом слоев, исчисляющимся десятками, сотнями и даже больше.\n",
        "\n",
        "Нейросети стали считаться доминирующим способом решения многих задач, являющихся прерогативой ИИ.\n",
        "\n",
        "<img src=\"https://i.ibb.co/mrY9jcZv/image.png\" width=800>\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Предпосылки бума использования ИНС**\n",
        "\n",
        "**Почему сейчас** (2010-2020 гг.), ведь основные идеи, фундаментальный математический аппарат ИНС были разработаны еще в середине прошлого века?\n",
        "\n",
        "* **Рост производительности компьютеров** (высокочастотные многоядерные процессоры есть почти в любом \"умном\" устройстве).\n",
        "* **Применение для вычислений графических ускорителей (GPU)** (операции при обучении нейросетей хорошо распараллеливаются).\n",
        "* **Резкое увеличение объемов накопленных данных** (эпоха Big Data).\n",
        "* **Появление новых продвинутых архитектур** (таких как трансформеры).\n",
        "* Всеобщая \"диджитализация\", в целом высокий уровень жизни обывателя, распространенность интернета и гаджетов, засилие социальных сетей, обилие аудиовизуального контента => **высокий запрос на развлечения.**"
      ],
      "metadata": {
        "id": "JWbr9a3IjTTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Преимущества и недостатки ИНС**\n",
        "\n",
        "<u>Преимущества:</u><br>\n",
        "* **Высокая эффективность.** Нейросети способны решать сложные задачи, обрабатывать большие объемы данных с большим количеством признаков и выявлять в них такие неочевидные закономерности, которые вручную обнаружить практически невозможно.\n",
        "* **Автоматическое извлечение признаков.** Нейросети способны самостоятельно извлекать важные признаки из данных.\n",
        "* **Робастность к зашумленным данным.**\n",
        "* **Высокая способность к распараллеливанию вычислений** при обучении и, как следствие, возможность использования графических процессоров (GPU), обладающих на порядки более высокой производительностью, чем центральные процессоры общего назначения (CPU).\n",
        "\n",
        "<u>Недостатки:</u><br>\n",
        "* Неинтерпретируемость.\n",
        "* Высокие требования к машинным ресурсам (по скорости вычислений, объему памяти...).\n",
        "* Необходимость в *больших* объемах данных для качественного обучения.\n",
        "* Достаточно высокий порог вхождения для осмысленного и эффективного использования.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Применение ИНС**\n",
        "\n",
        "**Развлекательное:** стилизация фотографий, генерация изображений и музыки по тексту, генерация текстов...\n",
        "\n",
        "<img src=\"https://i.ibb.co/HfKty4Tc/image.png\" width=500>\n",
        "\n",
        "\n",
        "\n",
        "**Практически полезное:** решение задач компьютерного зрения (выделение и распознавание объектов на изображении), перевод текста, преобразование речи в текст...\n",
        "\n",
        "<img src=\"https://i.ibb.co/jvpzwgf7/image.png\" width=600>\n",
        "\n",
        "ИНС успешно решают задачи, предполагающие обработку данных с гигантским числом признаков (изображения, видео, тексты, звуковые данные). Качественная обработка таких данных человеком невозможна ввиду чрезмерной трудоемкости.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **А вы знали?**\n",
        "\n",
        "**Современные смартфоны** используют нейронные сети для улучшения изображения, полученного с помощью камеры. Это позволяет программным путем компенсировать недостатки аппаратной части (недорогая некачественная оптика, маленькая матрица...).\n",
        "\n",
        "Компания Google широко использует возможности последних достижений в области ИИ и машинного обучения для улучшения снимков, сделанных с помощью ее фирменного приложения \"Камера\" на смартфонах линейки Pixel.\n",
        "\n",
        "<img src=\"https://i.ibb.co/LX9NpTR0/image.png\" width=500>\n",
        "\n",
        "\n",
        "Получается, что камера передает не реальную действительность, а некую искусственную картинку.\n",
        "\n",
        "<img src=\"https://i.ibb.co/ymCtdLBB/image.png\" width=100>\n",
        "\n",
        "**NVIDIA DLSS** (Deep Learning Super Sampling) – технология компании – разработчика графических чипов NVIDIA, реализованная в видеокартах серии RTX, позволяющая улучшать изображение в играх с помощью заранее предобученной нейронной сети.\n",
        "\n",
        "В результате повышается как качество, детализация, четкость картинки, так и частота FPS (количество кадров в секунду) по сравнению с \"честным\" рендерингом изображения с сопоставимыми параметрами.\n",
        "\n",
        "<img src=\"https://i.ibb.co/V0GSTm0f/image.png\" width=500>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Чего не могут нейросети?**\n",
        "\n",
        "* Заменить человека при принятии решений (потому что сильного ИИ не существует, ИНС не исключение, человеческий мозг все-таки устроен намного сложнее, чем любые существующие его модели).\n",
        "\n",
        "<img src=\"https://i.ibb.co/DD0R6kkD/image.png\" width=200>\n",
        "\n",
        "* Прогнозировать динамику ценных бумаг с высокой точностью.\n",
        "\n",
        "<img src=\"https://i.ibb.co/HLF5S0Nv/image.png\" width=150>\n",
        "\n",
        "* Принести вам кофе в постель.\n",
        "\n",
        "<img src=\"https://i.ibb.co/TBtfr1Rj/image.png\" width=300>"
      ],
      "metadata": {
        "id": "KzVICxWxz6xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Устройство нейронной сети**\n"
      ],
      "metadata": {
        "id": "QqpztV2bU4ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Искусственные нейронные сети родились как попытка воспроизвести принципы работы головного мозга, состоящего из нейронов.\n",
        "\n",
        "<img src=\"https://i.ibb.co/Ndk5s3MR/image.png\" width=600>\n",
        "\n",
        "#### **Биологический нейрон**\n",
        "\n",
        "**Нейрон** – это электрически возбудимая клетка, которая предназначена для приема извне, обработки, хранения, передачи и вывода вовне информации с помощью электрических и химических сигналов.\n",
        "\n",
        "Всего в человеческом мозгу **86 млрд** нейронов. Все они связаны между собой, объединяясь в сложную структуру.\n",
        "\n",
        "У нейрона есть ядро, которое накапливает электрический заряд.\n",
        "\n",
        "Также у него есть **входные** отростки (дендриты) и **выходной** (аксон).\n",
        "\n",
        "Через дендриты в нейрон от других нейронов поступает сигнал (нервный импульс). При накоплении в ядре определенного уровня заряда нейрон *срабатывает* и выдает сигнал на аксон.\n",
        "\n",
        "Аксон прикреплен к дендритам других нейронов через синапсы, которые могут изменять передаваемый сигнал. Если в синапсе сигнал увеличивается, он называется возбуждающим, иначе тормозящим.\n",
        "\n",
        "<u>Важные особенности биологических нейронов:</u><br>\n",
        "* Соседи нейрона **не равноправны.** Важность соседа определяется синапсом, соединяющим его аксон с дендритом нашего нейрона.\n",
        "\n",
        "<img src=\"https://i.ibb.co/LzthHtW2/image.png\" width=200>\n",
        "\n",
        "* Каждый нейрон может находиться **в двух состояниях:** возбужденном и невозбужденном. Если в ядре накоплен слишком большой сигнал, то нейрон переходит в возбужденное состояние.\n",
        "\n",
        "* Нейроны могут образовывать **циклы.** Импульс, испущенный из нейрона, может после всех преобразований вернуться обратно к нему на вход.\n",
        "\n",
        "Задача: представить нейрон в виде **математического объекта.**\n",
        "\n",
        "* У него должны быть входы и выход.\n",
        "* У него должна быть указана важность (сила) связей с соседними нейронами.\n",
        "* Он должен по достаточно простой формуле обрабатывать входные значения и передавать результат вычислений дальше. Формула должна быть простой, иначе сеть из нейронов будет очень требовать больших вычислительных мощностей.\n",
        "* Выходное значение нейрона должно моделировать его возбуждение.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Искусственный нейрон**\n",
        "\n",
        "<img src=\"https://i.ibb.co/jk1dJXVb/image.png\" width=300>\n",
        "\n",
        "Формула искусственного нейрона: $a=φ(∑_{i=1}^nw_ix_i+w_0)$\n",
        "\n",
        "Всего у нейрона может быть $n$ входов, на которые приходят значения $x_i$. Они могут приходить либо из внешней среды, либо с выходов других нейронов. При этом каждый вход имеет свой **вес** $w_i$, им выражается важность этого входа (*важность соседа,* если сигнал приходит от него).\n",
        "\n",
        "В искусственном нейроне есть сумматор, в котором вычисляется взвешенная сумма входов. К этой сумме прибавляется **смещение** $w_0$. Его смысл - порог возбуждения: разные нейроны должны\n",
        "возбуждаться с разным порогом значений, некоторые должны возбуждаться легко, некоторые с трудом.\n",
        "\n",
        "Затем к результату вычислений применяется **функция активации** $φ$. Если значение на выходе $a$ окажется достаточно велико, нейрон возбудился.\n",
        "\n"
      ],
      "metadata": {
        "id": "c_g24XhLVFd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Функции активации**\n",
        "\n",
        "Итак, значение на выходе нейрона вычисляется по формуле: $a=φ(x_1,x_2,...,x_n)$. Что за функция $φ$?\n",
        "\n",
        "Если строго следовать биологии, нужно взять **ступенчатую функцию** (функция Хэвисайда). В биологии происходит так: нейрон пребывал в покое, а потом вдруг взял и возбудился.\n",
        "\n",
        "$step(x)=\\begin{cases}\n",
        "0,&x < 0\\\\\n",
        "1,&x ≥ 0\n",
        "\\end{cases}$\n",
        "\n",
        "<img src=\"https://i.ibb.co/zh4VDg4y/Heaviside-svg.png\" width=300>\n",
        "\n",
        "Но у функции-ступеньки есть математические **недостатки:**\n",
        "* она разрывна;\n",
        "* ее производная равна 0 во всех точках своей области определения (а значит, для ее минимизации градиентный спуск не поможет).\n",
        "\n",
        "**А зачем минимизировать функцию активации?** Минимизировать нужно функцию потерь. А функция потерь любой модели машинного обучения вычисляется на базе разницы фактического значения целевого показателя $y$ и его модельного значения $\\hat{y}$. А модельное значение $\\hat{y}$ - это и есть значение на выходе модели, в нашем случае $a=φ(x_1,x_2,...,x_n)$. Следовательно, в процессе градиентного спуска для минимизации такой функции потерь рано или поздно придется вычислять градиент функции активации. И для ступеньки он окажется нулевым. Наш шарик никуда не покатится.\n",
        "\n",
        "$a_{n+1}=a_{n}-0$\n",
        "\n",
        "Убедили! Ступенька не подойдет. Может быть, подойдет **сигмоида?**\n",
        "\n",
        "**Сигмоидальные функции** - это семейство гладких монотонных возрастающих нелинейных функций, имеющих форму буквы S, которые часто применяются для \"сглаживания\" значений некоторой величины.\n",
        "\n",
        "Обычно под сигмоидой понимают логистическую функцию:\n",
        "\n",
        "$σ(x)=\\frac{1}{1+e^{-x}}$\n",
        "\n",
        "<img src=\"https://i.ibb.co/vxKPkGYc/Logistic-curve.png\" width=300>\n",
        "\n",
        "Область ее значений $[0;1]$.\n",
        "\n",
        "Нейрон с функцией активации \"сигмоида\" - это фактически **модель логистической регрессии.**\n",
        "\n",
        "Но есть и другие функции этого класса - например, гиперболический тангенс.\n",
        "\n",
        "Сигмоида похожа на ступенчатую функцию, которая описывает процесс\n",
        "активации биологического нейрона. По сути, она является ее гладкой\n",
        "аппроксимацией. Но и у нее есть **проблемы.**\n",
        "\n",
        "Производная сигмоиды ведет себя специфически. Она выражается через саму же сигмоиду.\n",
        "\n",
        "$σ'(x)=σ(x)(1-σ(x))$\n",
        "\n",
        "Это же хорошо? Производная легко вычисляется! Проще будет вычислять градиент.\n",
        "\n",
        "Проблемы начинаются, когда у нас не просто одна сигмоида, а **суперпозиция нескольких сигмоид.**\n",
        "\n",
        "$σ'(σ(x))=σ(σ(x))(1-σ(σ(x)))σ(x)(1-σ(x))$\n",
        "\n",
        "$σ'(σ(σ(x)))=σ(σ(σ(x)))(1-σ(σ(σ(x))))σ(σ(x))(1-σ(σ(x)))σ(x)(1-σ(x))$\n",
        "\n",
        "Сложная функция из сигмоид включает несколько множителей. Но все эти множители положительны и меньше 1, ведь $σ(x) \\in [0;1]$. А произведение таких чисел стремится к 0 с возрастанием их количества.\n",
        "\n",
        "Следовательно, **производная суперпозиции большого числа сигмоид примерно равна 0** при любом аргументе. А это - **затухание градиента.**\n",
        "\n",
        "А зачем вообще нужна суперпозиция сигмоид? У нас один нейрон, у него одна функция активации - одна сигмоида.\n",
        "\n",
        "В нейроне-то сигмоида одна, но нейронная **сеть** состоит не из одного нейрона. Выход одного нейрона соединен со входами других нейронов. Вот и возникает на выходе сети сложная функция из множества сигмоид.\n",
        "\n",
        "И даже значения первой производной сигмоиды почти нулевые:\n",
        "\n",
        "$σ'(5)=0,0067$<br>\n",
        "$σ'(10)=0,00005$\n",
        "\n",
        "Есть еще **гиперболический тангенс.** Отличие от сигмоиды: область значений не $[0;1]$, а $[-1;1]$.\n",
        "\n",
        "$th(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}$\n",
        "\n",
        "<img src=\"https://i.ibb.co/fdvPnNMR/Graph-Hyperbolic-Tangent-Function-Example-01.png\" width=350>\n",
        "\n",
        "А можно ли брать не S-образные функции (не похожие на ступеньку)?\n",
        "\n",
        "Практика показала, что можно. Часто оправдано моделировать нейрон не двумя состояниями (возбудился или нет), а некоторой числовой \"шкалой возбуждения\".\n",
        "\n",
        "<img src=\"https://i.ibb.co/rG7kMbkC/f67f480c40fbb47898f9014c94ac.jpg\" width=200>\n",
        "\n",
        "Для этого хорошо подходит функция **ReLU** (**Re**ctified **L**inear **U**nit).\n",
        "\n",
        "$ReLU(x)=max(0, x)$\n",
        "\n",
        "<img src=\"https://i.ibb.co/Mxc8gVp7/Relu-activation-function.png\" width=400>\n",
        "\n",
        "С функцией ReLU нейрон может неограниченно возбуждаться. В биологии происходит не так, но в ИНС это часто полезно.\n",
        "\n",
        "Функция ReLU является одной из наиболее популярных функций активации в нейронных сетях.\n",
        "\n",
        "**Еще некоторые функции активации:**\n",
        "\n",
        "<img src=\"https://i.ibb.co/jkn0fMDg/1-Zaf-Dv3-VUm60-Eh10-Oe-Ju1vw.webp\" width=500>\n",
        "\n",
        "**Leaky ReLU:** не зануляет отрицательные сигналы (в отличие от\n",
        "ReLU).<br>\n",
        "**ELU:** похожа на leaky ReLU и обладает ее преимуществами, но дороже в вычислении из-за экспоненты. Её стоит использовать в тех случаях, когда важна устойчивость к шумам в данных.\n",
        "\n",
        "Все эти функции активации являются нелинейными и добавляют **нелинейность** в нейрон.\n",
        "\n",
        "Но иногда функция активации может быть **линейной:** $f(x)=x$. Фактически это означает, что нейрон представляет собой обычную **линейную модель** без добавленной нелинейности.\n",
        "\n",
        "$a=∑_{i=1}^nw_ix_i+w_0$\n",
        "\n",
        "<br>\n",
        "\n",
        "**Справка по функциям активации:** *(из материала Ю. Пономаревой)*\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>\n",
        "Функция активации\n",
        "</th>\n",
        "\n",
        "<th>\n",
        "Плюсы\n",
        "</th>\n",
        "\n",
        "<th>\n",
        "Минусы\n",
        "</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "Линейная\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Меньше времени на вычисления\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Линейная функция\n",
        "2. Нефиксированный диапазон значений функции — [-∞,+∞]\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "Сигмоида\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нелинейная функция\n",
        "2. В диапазоне значений сигнала от -2.5 до 2.5<br>значения активации меняются очень быстро\n",
        "3. Фиксированный диапазон значений функции — [0,1]\n",
        "\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Затухают градиенты\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "Гиперболический тангенс\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нелинейная функция\n",
        "2. В диапазоне значений сигнала от -2.5 до 2.5<br>значения активации меняются очень быстро\n",
        "3. Фиксированный диапазон значений функции — [-1,1]\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Затухают градиенты\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "ReLU\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Меньше времени на вычисления\n",
        "2. Меньше вес у сети\n",
        "3. Нет проблемы затухающих градиентов\n",
        "    \n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нулевые градиенты у сигналов, которые меньше 0\n",
        "2. Нефиксированный диапазон значений функции\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "Leaky ReLU\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нет проблемы нулевых градиентов\n",
        "\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нужно подбирать значение alpha\n",
        "2. Нефиксированный диапазон значений функции\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "ELU\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Нет проблемы нулевых градиентов\n",
        "2. Имеются негативные выходы, что помогает<br>нейронной сети направлять веса в нужное направление\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "1. Больше времени на вычисления\n",
        "2. Нефиксированный диапазон значений функции\n",
        "3. Нужно подбирать значение alpha\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "\n",
        "**Пример.** Вычислим значение на выходе следующего нейрона в точке $(0.5,-1.7)$.\n",
        "\n",
        "<img src=\"https://i.ibb.co/rK1jbVKc/image.png\" width=200>\n",
        "\n",
        "$a(0.5,-1.7)=ReLU(0.4 \\cdot 0.5 + 0.18 \\cdot (-1.7) + 1.1)=max(0,0.994)=0.994$\n",
        "\n"
      ],
      "metadata": {
        "id": "cd87YRiSjXA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Объединение нейронов в сеть**\n",
        "\n",
        "Искусственные нейроны можно объединить в **нейронную сеть** таким образом, что выходы одних нейронов будут соединены со входами других нейронов. Причем **один выход** может быть соединен с **несколькими входами.**\n",
        "\n",
        "Теоретически нейроны можно соединять как угодно, но на практике существуют некоторые стандартные паттерны, по которым объединяются нейроны, так называемые **архитектуры нейронных сетей.**\n",
        "\n",
        "Обычно нейроны объединены в группы - **слои.** Слои располагаются последовательно друг за другом. Слои состоят из **одинаковых** нейронов (т.е. нейронов с одинаковыми количеством входов и функцией активации; веса во всех нейронах разные).\n",
        "\n",
        "<img src=\"https://i.ibb.co/MyNvs65R/image.png\" width=400>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://i.ibb.co/BV1Vd4w2/image.png\" width=170>\n",
        "\n",
        "**Входной** слой получает сигналы извне. Фактически во входном слое нет нейронов (нейрон имеет веса, сумматор и функцию активации), кружочки на схеме - это просто значения на входе сети.\n",
        "\n",
        "**Выходной** слой выдает результирующий сигнал. В нем присутствует минимум один нейрон (может быть и больше). Так как у каждого нейрона только один выход, количеством нейронов выходного слоя определяется размерность ответа всей нейронной сети (может быть одно число или несколько - зависит от решаемой задачи).\n",
        "\n",
        "**Скрытый слой** называется так потому, что он не взаимодействует с внешним миром напрямую.\n",
        "\n",
        "Скрытых слоев может быть **несколько.** Нейросеть с несколькими скрытыми слоями (более одного) называется **глубокой.** (Глубокое обучение – это машинное обучение на базе глубоких ИНС).\n",
        "\n",
        "В подобной нотации (с кружками в слоях) нейрон с двумя входами из примера выше можно представить так:\n",
        "\n",
        "<img src=\"https://i.ibb.co/q8yptBX/image.png\" width=100>\n",
        "\n",
        "Тут входной слой (2 входа) и выходной слой из одного нейрона. Скрытых слоев нет.\n",
        "\n"
      ],
      "metadata": {
        "id": "FTiPdRwV9m_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.** Рассмотрим сеть из двух последовательно соединенных нейронов.\n",
        "\n",
        "<u>Первый случай - один вход.</u>\n",
        "\n",
        "<img src=\"https://i.ibb.co/bM0QvVKH/image.png\" width=300>\n",
        "\n",
        "На входе: $x=2$.\n",
        "\n",
        "На выходе нейрона скрытого слоя: $ReLU(2 \\cdot 2-1)$.\n",
        "\n",
        "На выходе нейрона выходного слоя: $ReLU(-3 \\cdot выход\\_предыдущего\\_нейрона+1)$.\n",
        "\n",
        "Выход последнего нейрона - это выход всей сети. Подставим в его формулу значение выхода предыдущего нейрона:\n",
        "\n",
        "$ReLU(-3 \\cdot ReLU(2 \\cdot 2-1)+1)=ReLU(-3 \\cdot ReLU(3)+1)=ReLU(-8)=0$\n",
        "\n",
        "<u>Второй случай - три входа.</u>\n",
        "\n",
        "<img src=\"https://i.ibb.co/tTBMHN4s/image.png\" width=300>\n",
        "\n",
        "На входе: $x_1=4$, $x_2=-3$, $x_3=2$.\n",
        "\n",
        "На выходе нейрона скрытого слоя: $linear(4 \\cdot 2 -3 \\cdot 5 + 2 \\cdot (-1)-1)=4 \\cdot 2 -3 \\cdot 5 + 2 \\cdot (-1)-1$.\n",
        "\n",
        "На выходе нейрона выходного слоя: $ReLU(-3 \\cdot выход\\_предыдущего\\_нейрона+2)$.\n",
        "\n",
        "Раскроем формулу:\n",
        "\n",
        "$ReLU(-3 \\cdot (4 \\cdot 2 -3 \\cdot 5 + 2 \\cdot (-1)-1)+2)=ReLU(-3 \\cdot (-10)+2)=ReLU(32)=32$"
      ],
      "metadata": {
        "id": "5UdOT2oD8Oya"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
